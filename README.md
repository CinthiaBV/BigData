# Big Data - development 
# Project

### <p align="center" > TECNOLÓGICO NACIONAL DE MÉXICO INSTITUTO TECNOLÓGICO DE TIJUANA SUBDIRECCIÓN ACADÉMICA DEPARTAMENTO DE SISTEMAS Y COMPUTACIÓN PERIODO: Agosto-Diciembre  2020</p>

###  <p align="center">  Carrera: Ing. En Sistemas Computacionales. 
### <p align="center"> Materia: 	Datos Masivos (BDD-1704 SC9A	).</p>

### <p align="center">  Maestro: Jose Christian Romero Hernandez	</p>
### <p align="center">  No. de control y nombre del alumno: 15211916 - Vargas Garcia Cinthia Gabriela</p>
### <p align="center">  No. de control y nombre del alumno: 16210561 - Oliver Cardenas Jesus Alejandro</p>

### Index

&nbsp;&nbsp;&nbsp;[Proyect1](#Proyect1)    

&nbsp;&nbsp;&nbsp;[Link_Video](#Link-video)     

### &nbsp;&nbsp;Project .

#### &nbsp;&nbsp;&nbsp;&nbsp; Instructions.
Develop the following instructions in Spark with the Scala programming language.

Objective:
The goal of this hands-on test is to try to group customers from specific regions of a wholesaler. This based on the sales of some product categories.

The data sources are in the repository:
https://github.com/jcromerohdz/BigData/blob/master/Spark_clustering/Wholesale%20customers%20data.csv

    1. Import a simple Spark session.
    2. Use lines of code to minimize errors
    3. Create an instance of the Spark session
    4. Import the Kmeans library for the clustering algorithm.
    5. Load the Wholesale Customers Data dataset
    6. Select the following columns: Fresh, Milk, Grocery, Frozen, Detergents_Paper, Delicassen and call this set feature_data
    7. Import Vector Assembler and Vector
    8. Create a new Vector Assembler object for the feature columns as an input set, remembering that there are no labels
    9. Use the assembler object to transform feature_data
    10. Create a Kmeans model with K = 3
    11. Evaluate the groups using Within Set Sum of Squared Errors WSSSE and print the centroids.

Evaluation instructions
- Delivery time 4 days


